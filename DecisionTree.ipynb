{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e5d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, \n",
    "                            accuracy_score, confusion_matrix, ConfusionMatrixDisplay)\n",
    "from sklearn.ensemble import (RandomForestRegressor, RandomForestClassifier,\n",
    "                             AdaBoostRegressor, AdaBoostClassifier)\n",
    "from sklearn.datasets import fetch_california_housing, load_breast_cancer\n",
    "\n",
    "# ==============================================================================\n",
    "# REGRESSION PROBLEM (California Housing Dataset)\n",
    "# ==============================================================================\n",
    "\n",
    "# Load regression dataset\n",
    "housing = fetch_california_housing()\n",
    "X_reg = housing.data\n",
    "y_reg = housing.target\n",
    "feature_names_reg = housing.feature_names\n",
    "\n",
    "# a. Split data\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.3, random_state=42)\n",
    "\n",
    "# b. Build initial decision tree\n",
    "base_tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "base_tree_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# c. Check performance\n",
    "def evaluate_regression(model, X_train, X_test, y_train, y_test):\n",
    "    return {\n",
    "        'train_mse': mean_squared_error(y_train, model.predict(X_train)),\n",
    "        'test_mse': mean_squared_error(y_test, model.predict(X_test)),\n",
    "        'train_r2': r2_score(y_train, model.predict(X_train)),\n",
    "        'test_r2': r2_score(y_test, model.predict(X_test))\n",
    "    }\n",
    "\n",
    "base_reg_perf = evaluate_regression(base_tree_reg, X_train_reg, X_test_reg, y_train_reg, y_test_reg)\n",
    "\n",
    "# d. Cost Complexity Pruning\n",
    "path_reg = base_tree_reg.cost_complexity_pruning_path(X_train_reg, y_train_reg)\n",
    "ccp_alphas_reg = path_reg.ccp_alphas[:-1]  # Remove maximum alpha\n",
    "\n",
    "# Find optimal alpha using cross-validation\n",
    "scores_reg = []\n",
    "for alpha in ccp_alphas_reg:\n",
    "    tree_reg = DecisionTreeRegressor(ccp_alpha=alpha, random_state=42)\n",
    "    score = np.mean(cross_val_score(tree_reg, X_train_reg, y_train_reg, cv=5,\n",
    "                                   scoring='neg_mean_squared_error'))\n",
    "    scores_reg.append(-score)\n",
    "\n",
    "optimal_alpha_reg = ccp_alphas_reg[np.argmin(scores_reg)]\n",
    "\n",
    "# Build pruned tree\n",
    "pruned_tree_reg = DecisionTreeRegressor(ccp_alpha=optimal_alpha_reg, random_state=42)\n",
    "pruned_tree_reg.fit(X_train_reg, y_train_reg)\n",
    "pruned_reg_perf = evaluate_regression(pruned_tree_reg, X_train_reg, X_test_reg, y_train_reg, y_test_reg)\n",
    "\n",
    "# e. Random Forest\n",
    "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_reg.fit(X_train_reg, y_train_reg)\n",
    "rf_reg_perf = evaluate_regression(rf_reg, X_train_reg, X_test_reg, y_train_reg, y_test_reg)\n",
    "\n",
    "# f. AdaBoost with Decision Stumps\n",
    "ada_reg = AdaBoostRegressor(\n",
    "    DecisionTreeRegressor(max_depth=1),\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "ada_reg.fit(X_train_reg, y_train_reg)\n",
    "ada_reg_perf = evaluate_regression(ada_reg, X_train_reg, X_test_reg, y_train_reg, y_test_reg)\n",
    "\n",
    "# ==============================================================================\n",
    "# CLASSIFICATION PROBLEM (Breast Cancer Dataset)\n",
    "# ==============================================================================\n",
    "\n",
    "# Load classification dataset\n",
    "cancer = load_breast_cancer()\n",
    "X_clf = cancer.data\n",
    "y_clf = cancer.target\n",
    "feature_names_clf = cancer.feature_names\n",
    "\n",
    "# a. Split data\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.3, random_state=42)\n",
    "\n",
    "# b. Build initial decision tree\n",
    "base_tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "base_tree_clf.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "# c. Check performance\n",
    "def evaluate_classification(model, X_train, X_test, y_train, y_test):\n",
    "    return {\n",
    "        'train_acc': accuracy_score(y_train, model.predict(X_train)),\n",
    "        'test_acc': accuracy_score(y_test, model.predict(X_test))\n",
    "    }\n",
    "\n",
    "base_clf_perf = evaluate_classification(base_tree_clf, X_train_clf, X_test_clf, y_train_clf, y_test_clf)\n",
    "\n",
    "# d. Cost Complexity Pruning\n",
    "path_clf = base_tree_clf.cost_complexity_pruning_path(X_train_clf, y_train_clf)\n",
    "ccp_alphas_clf = path_clf.ccp_alphas[:-1]\n",
    "\n",
    "# Find optimal alpha using cross-validation\n",
    "scores_clf = []\n",
    "for alpha in ccp_alphas_clf:\n",
    "    tree_clf = DecisionTreeClassifier(ccp_alpha=alpha, random_state=42)\n",
    "    score = np.mean(cross_val_score(tree_clf, X_train_clf, y_train_clf, cv=5, scoring='accuracy'))\n",
    "    scores_clf.append(1 - score)  # Convert to error rate\n",
    "\n",
    "optimal_alpha_clf = ccp_alphas_clf[np.argmin(scores_clf)]\n",
    "\n",
    "# Build pruned tree\n",
    "pruned_tree_clf = DecisionTreeClassifier(ccp_alpha=optimal_alpha_clf, random_state=42)\n",
    "pruned_tree_clf.fit(X_train_clf, y_train_clf)\n",
    "pruned_clf_perf = evaluate_classification(pruned_tree_clf, X_train_clf, X_test_clf, y_train_clf, y_test_clf)\n",
    "\n",
    "# e. Random Forest\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train_clf, y_train_clf)\n",
    "rf_clf_perf = evaluate_classification(rf_clf, X_train_clf, X_test_clf, y_train_clf, y_test_clf)\n",
    "\n",
    "# f. AdaBoost with Decision Stumps\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "ada_clf.fit(X_train_clf, y_train_clf)\n",
    "ada_clf_perf = evaluate_classification(ada_clf, X_train_clf, X_test_clf, y_train_clf, y_test_clf)\n",
    "\n",
    "# ==============================================================================\n",
    "# Visualization and Results\n",
    "# ==============================================================================\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Regression Results\n",
    "plt.subplot(2, 2, 1)\n",
    "models_reg = ['Base Tree', 'Pruned Tree', 'Random Forest', 'AdaBoost']\n",
    "mse_test_reg = [base_reg_perf['test_mse'], pruned_reg_perf['test_mse'],\n",
    "               rf_reg_perf['test_mse'], ada_reg_perf['test_mse']]\n",
    "plt.bar(models_reg, mse_test_reg)\n",
    "plt.title('Regression Model Comparison (Test MSE)')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(ccp_alphas_reg, scores_reg)\n",
    "plt.scatter(optimal_alpha_reg, np.min(scores_reg), c='red')\n",
    "plt.title('Regression: Cost Complexity Pruning')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('Cross-Validated MSE')\n",
    "\n",
    "# Classification Results\n",
    "plt.subplot(2, 2, 3)\n",
    "models_clf = ['Base Tree', 'Pruned Tree', 'Random Forest', 'AdaBoost']\n",
    "acc_test_clf = [base_clf_perf['test_acc'], pruned_clf_perf['test_acc'],\n",
    "               rf_clf_perf['test_acc'], ada_clf_perf['test_acc']]\n",
    "plt.bar(models_clf, acc_test_clf)\n",
    "plt.title('Classification Model Comparison (Test Accuracy)')\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "ConfusionMatrixDisplay.from_estimator(ada_clf, X_test_clf, y_test_clf)\n",
    "plt.title('AdaBoost Confusion Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Regression Results:\")\n",
    "print(f\"Base Tree - Train R²: {base_reg_perf['train_r2']:.3f}, Test R²: {base_reg_perf['test_r2']:.3f}\")\n",
    "print(f\"Pruned Tree - Test R²: {pruned_reg_perf['test_r2']:.3f}\")\n",
    "print(f\"Random Forest - Test R²: {rf_reg_perf['test_r2']:.3f}\")\n",
    "print(f\"AdaBoost - Test R²: {ada_reg_perf['test_r2']:.3f}\\n\")\n",
    "\n",
    "print(\"Classification Results:\")\n",
    "print(f\"Base Tree - Test Accuracy: {base_clf_perf['test_acc']:.3f}\")\n",
    "print(f\"Pruned Tree - Test Accuracy: {pruned_clf_perf['test_acc']:.3f}\")\n",
    "print(f\"Random Forest - Test Accuracy: {rf_clf_perf['test_acc']:.3f}\")\n",
    "print(f\"AdaBoost - Test Accuracy: {ada_clf_perf['test_acc']:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
